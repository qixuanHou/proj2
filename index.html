<html>
<head>
<title>Computer Vision Project</title>
<link href='http://fonts.googleapis.com/css?family=Nunito:300|Crimson+Text|Droid+Sans+Mono' rel='stylesheet' type='text/css'>
<link rel="stylesheet" title="Default" href="styles/github.css">
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>  

<link rel="stylesheet" href="highlighting/styles/default.css">
<script src="highlighting/highlight.pack.js"></script>

<style type="text/css">
body {
	margin: 0px;
	width: 100%;
	font-family: 'Crimson Text', serif;
	font-size: 20px;
	background: #fcfcfc;
}
h1 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 28px;
	margin: 25px 0px 0px 0px;
	text-transform: lowercase;

}

h2 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 32px;
	margin: 15px 0px 35px 0px;
	color: #333;	
	word-spacing: 3px;
}

h3 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 26px;
	margin: 10px 0px 10px 0px;
	color: #333;
	word-spacing: 2px;
}
h4 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 22px;
	margin: 10px 0px 10px 0px;
	color: #333;
	word-spacing: 2px;
}

h5 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 18px;
	margin: 10px 0px 10px 0px;
	color: #111;
	word-spacing: 2px;
}

p, li {
	color: #444;
}

a {
	color: #DE3737;
}

.container {
	margin: 0px auto 0px auto;
	width: 960px;
}

#header {
	background: #333;
	width: 100%;
}

#headersub {
	color: #ccc;
	width: 960px;
	margin: 0px auto 0px auto;
	padding: 20px 0px 20px 0px;
}

.chart {
	width: 480px;
}
.lol {
	font-size: 16px;
	color: #888;
	font-style: italic;
}
.sep {
	height: 1px;
	width: 100%;
	background: #999;
	margin: 20px 0px 20px 0px;
}
.footer{
	font-size: 16px;
}
.latex {
	width: 100%;
}

.latex img {
	display: block;
	margin: 0px auto 0px auto;
}

pre {
	font-family: 'Droid Sans Mono';
	font-size: 14px;
}

td img {
  vertical-align: middle;
}

#contents a {
}
</style>
<script type="text/javascript">
    hljs.initHighlightingOnLoad();
</script>
</head>
<body>
<div id="header" >
<div id="headersub">

</div>
</div>
<div class="container">

<h2>Project 2: Local Feature Matching</h2>

<div style="float: right; padding: 20px">
<img src="best.jpg" style="height: 280px" />
<p style="font-size: 14px">Best Match Results with Notre Dame</p>
</div>

<p> 	
The goal of the project is to do a local feature matching. The pipeline is
</p>
<ol>
<li>get interest point</li>
<li>describe local features</li>
<li>match the features</li>
</ol>
<h2>Steps</h2>
<h3>Get Interest Point</h3>
<p>
1. compute the horizontal and vertical derivatives of the image Ix and Iy 
</p>
<p>
I use Matlab function 
<pre><code>
[imagex, imagey] = imgradientxy(image);
</code></pre>
to get the derivatives
</p>
<p>
2. Computer the three images corresponding to the outer products of these gradients 
</p>
<p>
3. Convolve each image with a larger Gaussian
</p>
<p>
I use Matlab function 
<pre><code>
large = fspecial('Gaussian');
imagexf = imfilter(imagex2, large);
</code></pre>
to do this step. 
</p>

<p>
4.	Compute a scalar interest measure 
</p> 
<p>
R = det(H) - k * (trace(H) ^ 2)  Apply the function to each dot in the matrix
</p>
<p>
5.	Find local maxima 
</p>

<p>I use Matlab function imregionalmax to find local maxima. </p>
<pre><code>
matr = imregionalmax(Rs);
[value, I] = sort(Rs(matr), 'descend');
nRs = matr .* Rs;
threshold = value(5000);
[x, y] = find(nRs > threshold);
</code></pre>

<h3>Describe Local Features</h3>
<p>
I used a SIFT-like feature. I calculate the gradient of the image with 
<pre><code>
[mag, dir] = imgradient(image);
</code></pre>
At each interest point, I built histogram based on the orientations of each neaby pixels.
Based on feature width, I divided the feature into 4*4 grids and for each cell in the grid, I created 8 bins for 8 set of orientations. I have a seperate function to build histogram at each feature. 
<pre><code>
[aDes] = hist(dir, i, j, s)
</code></pre>
dir is the direction matrix I computed previously. i and j are coornidates of left upper corner of the small cell. s is the size of feature_width/4. The function returns aDes, a normalized 1*8 vectors. 

</p>

<h3>Match the Features</h3>
<p>
I implemented "ration test" to find matches and get top 100 points at the end of the step.</p>
<pre><code>
confidences = confidences(1:100);
matches = matches(1:100, :);
</code></pre>


<h2>Results</h2>
<h3>Results with cheat_interesting_points</h3>
The matches are generated with cheat_interesting_points. From left to right, from top to bottom, I increased the size of the feature_width.
<li>image 1 - feature_width = 16 - accuracy = 0.72</li>
<li>image 2 - feature_width = 20 - accuracy = 0.79</li>
<li>image 3 - feature_width = 24 - accuracy = 0.82</li>
<li>image 4 - feature_width = 36 - accuracy = 0.82</li>
<li>image 5 - feature_width = 40 - accuracy = 0.86</li>
<li>image 6 - feature_width = 48 - accuracy = 0.86</li>


<table border=1>
<tr>
<td>
<img src="1/1.jpg" width="33%"/>
<img src="1/2.jpg"  width="33%"/>
<img src="1/3.jpg" width="33%"/>

</td>
</tr>

<tr>
<td>
<img src="1/4.jpg" width="33%"/>
<img src="1/5.jpg"  width="33%"/>
<img src="1/6.jpg" width="33%"/>

</td>
</tr>
</table>

<p>
The feature_width affects the accuracy of the matches. If the width is too small, the local feature cannot describe the feature precisely enough, but if the width is too large, it is hard to find matches. </p>

<p></p>
<p></p>
<p>The matches are generated with cheat_interesting_points. From left to right, from top to bottom, I increased the size of the feature_width.
<li>image 1 - feature_width = 16 - accuracy = 0.4</li>
<li>image 2 - feature_width = 24 - accuracy = 0.61</li>
<li>image 3 - feature_width = 40 - accuracy = 0.86</li>
<li>image 4 - feature_width = 44 - accuracy = 0.91</li>

<table border=1>
<tr>
<td>
<img src="2/1.jpg" width="49%"/>
<img src="2/2.jpg"  width="49%"/>

</td>
</tr>
<tr>
<td>
<img src="2/3.jpg" width="49%"/>
<img src="2/4.jpg" width="49%"/>
</td>
</tr>
</table>
<p></p>
<p></p>
<p>The matches are generated with cheat_interesting_points. From left to right, from top to bottom, I increased the size of the feature_width.
<li>image 1 - feature_width = 32 - accuracy = 0.21</li>
<li>image 2 - feature_width = 52 - accuracy = 0.26</li>


<table border=1>
<tr>
<td>
<img src="3/1.jpg" width="49%"/>
<img src="3/2.jpg"  width="49%"/>

</td>
</tr>

</table>
<p>This test image generates lowest accuracy. I think the different size of image causes the low accuracy. If we can first resize the image to be similar. We might get better results.
</p>



<h3>Results with get_interesting_points</h3>
<p>I changed the number of interesting points returned from get_interesting_points by changing 5000 to 10000 and 15000.</p>

<pre><code>
threshold = value(5000);
[x, y] = find(nRs > threshold);

</code></pre>
From left to right, we have images 
<li>image 1 - feature_width = 24 - interesting_points = 5000 - accuracy = 0.89</li>
<li>image 2 - feature_width = 24 - interesting_points = 10000 - accuracy = 0.90</li>
<li>image 3 - feature_width = 24 - interesting_points = 15000  - accuracy = 0.94</li>

Even though the accuracy does increase as we increase the number of interesting points, the speed of the algorithm descreases dramatically.

<table>
<tr>
<td>
<img src="1.jpg" width="33%"/>
<img src="2.jpg"  width="33%"/>
<img src="3.jpg" width="33%"/>

</td>
</tr>
</table>



For the other two test image, I got 84% on the image at the left and I got only 3% on the image at the right.
<table>
<tr>
<td>
<img src="2_1.jpg" width="49%"/>
<img src="3_1.jpg"  width="49%"/>
</td>
</tr>
</table>
</div>
</body>
</html>
